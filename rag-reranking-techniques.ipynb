{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CJpEEfRMM-Ig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "100559ab-dcdc-4830-d7c6-db6c20a4db48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.9/323.9 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq langchain faiss-cpu langchain-community langchain-core langchain-groq PyMuPDF tiktoken bs4 fastembed tavily-python rerankers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import warnings\n",
        "from langchain_community.retrievers import TavilySearchAPIRetriever\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from tavily.errors import InvalidAPIKeyError\n",
        "from langchain.schema.runnable import Runnable\n",
        "from typing import cast"
      ],
      "metadata": {
        "id": "rTYa29-gpbkQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "c4XCi7WkqIf-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_web(query: str) -> list:\n",
        "    \"\"\"Search the web.\"\"\"\n",
        "    try:\n",
        "        tavily_tool = TavilySearchAPIRetriever(\n",
        "            k=10,\n",
        "            #api_key=os.getenv(\"TAVILY_API_KEY\"),\n",
        "            api_key =userdata.get('TAVILY_API_KEY'),\n",
        "            max_tokens=10000,\n",
        "            search_depth='advanced'\n",
        "        )\n",
        "        results = tavily_tool.invoke(query)\n",
        "        if not results:\n",
        "            return [\"No relevant context found.\"]\n",
        "        return [result.page_content for result in results]\n",
        "    except InvalidAPIKeyError as e:\n",
        "        return [\"Invalid API key.\"]\n",
        "    except Exception as e:\n",
        "        return [f\"Error occurred while fetching context: {str(e)}\"]"
      ],
      "metadata": {
        "id": "mt2W4iYCqN8u"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# groq_key = os.getenv(\"GROQ_API_KEY\")\n",
        "# tavily_key = os.getenv(\"TAVILY_API_KEY\")\n",
        "from google.colab import userdata\n",
        "groq_key = userdata.get('GROQ_API_KEY')\n"
      ],
      "metadata": {
        "id": "5btPS-skqOTN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(\n",
        "        api_key=groq_key,\n",
        "        model='llama-3.2-1b-preview',\n",
        "        temperature=0,\n",
        "        max_retries=3,\n",
        "        timeout=None,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "llm.invoke(\"What is AI\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDQTTYjBqRBd",
        "outputId": "5ed96778-281f-4cb1-fbf8-4ccd8c44f96a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Artificial Intelligence (AI) refers to the development of computer systems that can perform tasks that typically require human intelligence, such as:\\n\\n1. Learning: AI systems can learn from data and improve their performance over time.\\n2. Problem-solving: AI systems can analyze data, identify patterns, and make decisions.\\n3. Reasoning: AI systems can draw conclusions based on data and rules.\\n4. Perception: AI systems can interpret and understand data from sensors and other sources.\\n5. Natural Language Processing (NLP): AI systems can understand and generate human language.\\n\\nAI can be categorized into several types, including:\\n\\n1. Narrow or Weak AI: Designed to perform a specific task, such as facial recognition or language translation.\\n2. General or Strong AI: Designed to perform any intellectual task that a human can, such as reasoning, problem-solving, and learning.\\n3. Superintelligence: Significantly more intelligent than the best human minds, with capabilities that could potentially surpass human intelligence.\\n\\nAI has many applications across various industries, including:\\n\\n1. Healthcare: AI can help diagnose diseases, personalize treatment plans, and improve patient outcomes.\\n2. Finance: AI can help with risk analysis, portfolio management, and customer service.\\n3. Transportation: AI can help with route optimization, traffic management, and autonomous vehicles.\\n4. Education: AI can help with personalized learning, grading, and student assessment.\\n5. Customer Service: AI can help with chatbots, virtual assistants, and customer support.\\n\\nSome of the key benefits of AI include:\\n\\n1. Improved accuracy and efficiency\\n2. Enhanced decision-making\\n3. Increased productivity\\n4. Better customer experience\\n5. Improved safety and security\\n\\nHowever, AI also raises several concerns, including:\\n\\n1. Job displacement\\n2. Bias and fairness\\n3. Data privacy and security\\n4. Ethics and accountability\\n5. Dependence on technology\\n\\nOverall, AI has the potential to transform various aspects of our lives, but it is essential to address the challenges and concerns associated with its development and deployment.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 410, 'prompt_tokens': 38, 'total_tokens': 448, 'completion_time': 0.123154658, 'prompt_time': 0.010614829, 'queue_time': 0.00031138900000000046, 'total_time': 0.133769487}, 'model_name': 'llama-3.2-1b-preview', 'system_fingerprint': 'fp_e9a4952513', 'finish_reason': 'stop', 'logprobs': None}, id='run-b6a1e525-f6a6-40d1-8287-877812d30b2c-0', usage_metadata={'input_tokens': 38, 'output_tokens': 410, 'total_tokens': 448})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"You are a helpful assistant.\n",
        "\n",
        "            Answer the question according to the query and given context:\n",
        "            Question: {question}\n",
        "            Context: {context}\n",
        "            Provide an accurate response in bullet points but don't mention it in the response,\n",
        "            the answer should be brief (max 5 lines/points).\n",
        "            Do not hallucinate.\n",
        "    \"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(prompt)"
      ],
      "metadata": {
        "id": "CoEEY6n2qU3u"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt_template | llm"
      ],
      "metadata": {
        "id": "ULdms10AsEb-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = input(\"\")\n",
        "context = search_web(query)\n",
        "response = chain.invoke({'question':query,\n",
        "                         'context':context})\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "yFxO1kRPsNA-",
        "outputId": "24360cfb-4fb6-4d72-a1c7-259621c29e3e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "what is ai\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Here's an accurate response in bullet points:\\n\\n• AI, also known as Artificial intelligence, is a technology with human-like problem-solving capabilities.\\n• AI is a set of technologies that enable computers to perform a variety of advanced functions.\\n• Machine learning, generative AI, and deep learning are key areas of AI research.\\n• AI has various applications, including image recognition, natural language processing, and predictive analytics.\\n• The field of AI is constantly evolving, with new breakthroughs and challenges emerging regularly.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 1"
      ],
      "metadata": {
        "id": "NIVEPLZkiSFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8W9N3lUs_ut",
        "outputId": "6e219b0c-f51f-45f6-8189-20eeca04b1b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank_bm25) (1.26.4)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "tokenized_corpus = [doc.split() for doc in context]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "scores = bm25.get_scores(query.split())\n",
        "scored_docs = sorted(zip(context, scores), key=lambda x: x[1], reverse=True)\n",
        "top3_doc=[doc for doc, _ in scored_docs[:3]]\n",
        "response = chain.invoke({'question':query,\n",
        "                         'context':top3_doc})\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "9Q3G733Ovxjs",
        "outputId": "f570dd0c-d2dd-4b65-e9bc-b4de73f4fdc3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Here's an accurate response in bullet points:\\n\\n• Artificial intelligence (AI) refers to a set of technologies that enable computers to perform advanced functions, including language understanding, data analysis, and decision-making.\\n• AI is a field of science concerned with building computers and machines that can reason, learn, and act in a way that would normally require human intelligence.\\n• Machine learning and deep learning are two primary types of AI, used for data analytics, predictions, and forecasting, object categorization, and natural language processing.\\n• AI can be used in various applications, including chatbots, computer vision, and natural language processing, to perform tasks that previously only humans can do.\\n• The development and deployment of AI technologies are driven by the increasing availability of data, computing power, and machine learning algorithms.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 2"
      ],
      "metadata": {
        "id": "gnDZWYxqjGdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "doc_vectors = vectorizer.fit_transform(context)\n",
        "query_vector = vectorizer.transform([query])\n",
        "similarity = cosine_similarity(query_vector,doc_vectors).flatten()\n",
        "scored_docs = sorted(zip(context, similarity), key=lambda x: x[1], reverse=True)\n",
        "top3_doc = [doc for doc, _ in scored_docs[:3]]"
      ],
      "metadata": {
        "id": "UMceX6a0wvld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f242b8f2-4b08-404b-a661-5a433619cea1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Solution\\nSolution\\nSolution\\nSolution\\nSolution\\nSolution\\nTake the next step\\nStart\\nbuilding on Google Cloud with $300 in free credits and 20+\\nalways free products.\\n Artificial intelligence (AI) is a set of technologies\\nthat enable computers to perform a variety of advanced\\nfunctions, including the ability to\\nsee,\\nunderstand and\\ntranslate spoken and written language,\\nanalyze data,\\nmake recommendations, and more.\\n Artificial intelligence\\ndefined\\nArtificial intelligence is a field of science\\nconcerned with building computers and machines that\\ncan reason, learn, and act in such a way that would\\nnormally require human intelligence or that involves\\ndata whose scale exceeds what humans can\\nanalyze.\\n By using products like\\nVertex AI,\\nCCAI,\\nDocAI,\\nor AI APIs, organizations can make sense of all the data\\nthey’re producing, collecting, or otherwise analyzing,\\nno matter what format it’s in, to make actionable\\nbusiness decisions.\\n On an operational level for business use, AI is a\\nset of technologies that are based primarily on\\nmachine learning and deep learning, used for data\\nanalytics, predictions and forecasting, object\\ncategorization, natural language processing,\\nrecommendations, intelligent data retrieval, and\\nmore.\\n',\n",
              " 'Directly underneath AI, we have machine learning, which involves creating models by training an algorithm to make predictions or decisions based on data. Generative AI, sometimes called \"gen AI\", refers to deep learning models that can create complex original content—such as long-form text, high-quality images, realistic video or audio and more—in response to a user’s prompt or request. Another option for improving a gen AI app\\'s performance is retrieval augmented generation (RAG), a technique for extending the foundation model to use relevant sources outside of the training data to refine the parameters for greater accuracy or relevance. With these new generative AI practices, deep-learning models can be pretrained on large amounts of data. Train, validate, tune and deploy generative AI, foundation models and machine learning capabilities with IBM watsonx.ai, a next-generation enterprise studio for AI builders.',\n",
              " 'Artificial Intelligence (AI) is the development of computer systems that perform tasks requiring human intelligence. Learn about the evolution, types, applications, and future of AI, as well as its importance and challenges.']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 3"
      ],
      "metadata": {
        "id": "7qDGJdEQmH_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM8junIkjXf1",
        "outputId": "e469722a-afb3-4f4d-e862-292392a3e007"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "model_name = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "inputs = tokenizer(\n",
        "        [(query, doc) for doc in context],\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\",\n",
        "        max_length=512,\n",
        "    )\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "with torch.no_grad():\n",
        "      scores = model(**inputs).logits.squeeze(-1)\n",
        "scored_docs = sorted(zip(context, scores.tolist()), key=lambda x: x[1], reverse=True)\n",
        "top3_doc = [doc for doc, _ in scored_docs[:3]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYSSJF3Cmi61",
        "outputId": "baddf206-fb45-4b50-87c7-7c9ddff824de"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AI, also known as Artificial intelligence, is a technology with human-like problem-solving capabilities. AI in action appears to simulate human intelligence—it can recognize images, write poems, and make data-based predictions.',\n",
              " 'AI is a technical and scientific field that generates outputs for human-defined objectives using data analysis, machine learning and reasoning. Learn about the types, applications and impact of AI, as well as the history and governance of the technology.',\n",
              " 'Artificial Intelligence (AI) is the development of computer systems that perform tasks requiring human intelligence. Learn about the evolution, types, applications, and future of AI, as well as its importance and challenges.']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 4"
      ],
      "metadata": {
        "id": "1X5O72P6nqV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OksYkQpfnA8V",
        "outputId": "4169fd0f-1ada-4083-9aaa-2a154a1ae04a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.27.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "query_embedding = model.encode(query, convert_to_tensor=True)\n",
        "doc_embeddings = model.encode(context, convert_to_tensor=True)\n",
        "similarities = util.cos_sim(query_embedding, doc_embeddings)[0].cpu().numpy()\n",
        "scored_docs = sorted(\n",
        "        zip(context, similarities), key=lambda x: x[1], reverse=True\n",
        "    )\n",
        "top3_doc = [doc for doc, _ in scored_docs[:3]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMklx4NVn6GV",
        "outputId": "6e1480d7-fcc4-4761-ca4b-3f35c7ad8b25"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AI, also known as Artificial intelligence, is a technology with human-like problem-solving capabilities. AI in action appears to simulate human intelligence—it can recognize images, write poems, and make data-based predictions.',\n",
              " 'Artificial Intelligence (AI) is the development of computer systems that perform tasks requiring human intelligence. Learn about the evolution, types, applications, and future of AI, as well as its importance and challenges.',\n",
              " 'AI is a technical and scientific field that generates outputs for human-defined objectives using data analysis, machine learning and reasoning. Learn about the types, applications and impact of AI, as well as the history and governance of the technology.']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 5"
      ],
      "metadata": {
        "id": "0Xcb1ABtpyyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0i1vH7-loGiF",
        "outputId": "b10f7ea6-dd95-4a37-d2e0-22148a11958d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "query_doc = nlp(query)\n",
        "scored_docs = sorted(\n",
        "        context,\n",
        "        key=lambda doc: query_doc.similarity(nlp(doc)),\n",
        "        reverse=True,\n",
        "    )"
      ],
      "metadata": {
        "id": "CsDVjMOEp32W"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4h7_81Lcp9QW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}