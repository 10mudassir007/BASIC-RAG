{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "CJpEEfRMM-Ig"
      },
      "outputs": [],
      "source": [
        "!pip install -Uq langchain faiss-cpu langchain-community langchain-core langchain-groq PyMuPDF tiktoken bs4 fastembed tavily-python rerankers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import warnings\n",
        "from langchain_community.retrievers import TavilySearchAPIRetriever\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from tavily.errors import InvalidAPIKeyError\n",
        "from langchain.schema.runnable import Runnable\n",
        "from typing import cast"
      ],
      "metadata": {
        "id": "rTYa29-gpbkQ"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "c4XCi7WkqIf-"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_web(query: str) -> list:\n",
        "    \"\"\"Search the web.\"\"\"\n",
        "    try:\n",
        "        tavily_tool = TavilySearchAPIRetriever(\n",
        "            k=10,\n",
        "            #api_key=os.getenv(\"TAVILY_API_KEY\"),\n",
        "            api_key =userdata.get('TAVILY_API_KEY'),\n",
        "            max_tokens=10000,\n",
        "            search_depth='advanced'\n",
        "        )\n",
        "        results = tavily_tool.invoke(query)\n",
        "        if not results:\n",
        "            return [\"No relevant context found.\"]\n",
        "        return [result.page_content for result in results]\n",
        "    except InvalidAPIKeyError as e:\n",
        "        return [\"Invalid API key.\"]\n",
        "    except Exception as e:\n",
        "        return [f\"Error occurred while fetching context: {str(e)}\"]"
      ],
      "metadata": {
        "id": "mt2W4iYCqN8u"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# groq_key = os.getenv(\"GROQ_API_KEY\")\n",
        "# tavily_key = os.getenv(\"TAVILY_API_KEY\")\n",
        "from google.colab import userdata\n",
        "groq_key = userdata.get('GROQ_API_KEY')\n"
      ],
      "metadata": {
        "id": "5btPS-skqOTN"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(\n",
        "        api_key=groq_key,\n",
        "        model='llama-3.2-1b-preview',\n",
        "        temperature=0,\n",
        "        max_retries=3,\n",
        "        timeout=None,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "llm.invoke(\"What is AI\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDQTTYjBqRBd",
        "outputId": "456c4c33-93a1-49c4-ce78-8b2ec671af69"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Artificial Intelligence (AI) refers to the development of computer systems that can perform tasks that typically require human intelligence, such as:\\n\\n1. Learning: AI systems can learn from data and improve their performance over time.\\n2. Problem-solving: AI systems can analyze data, identify patterns, and make decisions.\\n3. Reasoning: AI systems can draw conclusions based on data and rules.\\n4. Perception: AI systems can interpret and understand data from sensors and other sources.\\n5. Natural Language Processing (NLP): AI systems can understand and generate human language.\\n\\nAI can be categorized into several types, including:\\n\\n1. Narrow or Weak AI: Designed to perform a specific task, such as facial recognition or language translation.\\n2. General or Strong AI: Designed to perform any intellectual task that a human can, such as reasoning, problem-solving, and learning.\\n3. Superintelligence: Significantly more intelligent than the best human minds, with capabilities that could potentially surpass human intelligence.\\n\\nAI has many applications across various industries, including:\\n\\n1. Healthcare: AI can help diagnose diseases, personalize treatment plans, and improve patient outcomes.\\n2. Finance: AI can help with risk analysis, portfolio management, and customer service.\\n3. Transportation: AI can help with route optimization, traffic management, and autonomous vehicles.\\n4. Education: AI can help with personalized learning, grading, and student assessment.\\n5. Customer Service: AI can help with chatbots, virtual assistants, and customer support.\\n\\nSome of the key benefits of AI include:\\n\\n1. Improved accuracy and efficiency\\n2. Enhanced decision-making\\n3. Increased productivity\\n4. Better customer experience\\n5. Improved safety and security\\n\\nHowever, AI also raises several concerns, including:\\n\\n1. Job displacement\\n2. Bias and fairness\\n3. Data privacy and security\\n4. Ethics and accountability\\n5. Dependence on technology\\n\\nOverall, AI has the potential to transform various aspects of our lives, but it is essential to address the challenges and concerns associated with its development and deployment.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 410, 'prompt_tokens': 38, 'total_tokens': 448, 'completion_time': 0.121194169, 'prompt_time': 0.010569125, 'queue_time': 0.0008922139999999988, 'total_time': 0.131763294}, 'model_name': 'llama-3.2-1b-preview', 'system_fingerprint': 'fp_e9a4952513', 'finish_reason': 'stop', 'logprobs': None}, id='run-476c7b3c-c05e-4da8-96aa-49f91120e222-0', usage_metadata={'input_tokens': 38, 'output_tokens': 410, 'total_tokens': 448})"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"You are a helpful assistant.\n",
        "\n",
        "            Answer the question according to the query and given context:\n",
        "            Question: {question}\n",
        "            Context: {context}\n",
        "            Provide an accurate response in bullet points but don't mention it in the response,\n",
        "            the answer should be brief (max 5 lines/points).\n",
        "            Do not hallucinate.\n",
        "    \"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(prompt)"
      ],
      "metadata": {
        "id": "CoEEY6n2qU3u"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt_template | llm"
      ],
      "metadata": {
        "id": "ULdms10AsEb-"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = input(\"\")\n",
        "context = search_web(query)\n",
        "response = chain.invoke({'question':query,\n",
        "                         'context':context})\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "yFxO1kRPsNA-",
        "outputId": "66eda06c-4dbf-493f-a51e-3a1e647ad1a4"
      },
      "execution_count": 76,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "what is cv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Here are the key points about CVs:\\n\\n• A CV is a short written summary of a person's career, qualifications, and education.\\n• It is used in various fields, including academia, science, and research.\\n• A CV is a detailed list of achievements, education, and work experience.\\n• It is typically 1-2 pages long and provides an in-depth review of a person's professional history.\\n• A CV is used for job applications in academia, science, and research, as well as in the US and EU.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 1"
      ],
      "metadata": {
        "id": "NIVEPLZkiSFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8W9N3lUs_ut",
        "outputId": "40f3cd8f-eef8-4dfc-e7af-ed67219d0b36"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank_bm25) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "tokenized_corpus = [doc.split() for doc in context]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "scores = bm25.get_scores(query.split())\n",
        "scored_docs = sorted(zip(context, scores), key=lambda x: x[1], reverse=True)\n",
        "top3_doc=[doc for doc, _ in scored_docs[:3]]\n",
        "response = chain.invoke({'question':query,\n",
        "                         'context':top3_doc})\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "9Q3G733Ovxjs",
        "outputId": "7bbc940d-077c-4350-e138-8f010b5d7076"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Here are the key points about CVs:\\n\\n• A CV is a comprehensive document listing academic and professional experience.\\n• It is a detailed summary of your life, usually more than two pages long.\\n• The main difference between a CV and a resume is its length and purpose.\\n• A CV is used for academic purposes, while a resume is for job search.\\n• It typically includes information about your education, work experience, and skills.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 2"
      ],
      "metadata": {
        "id": "gnDZWYxqjGdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "doc_vectors = vectorizer.fit_transform(context)\n",
        "query_vector = vectorizer.transform([query])\n",
        "similarity = cosine_similarity(query_vector,doc_vectors).flatten()\n",
        "scored_docs = sorted(zip(context, similarity), key=lambda x: x[1], reverse=True)\n",
        "top3_doc = [doc for doc, _ in scored_docs[:3]]"
      ],
      "metadata": {
        "id": "UMceX6a0wvld"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 3"
      ],
      "metadata": {
        "id": "7qDGJdEQmH_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM8junIkjXf1",
        "outputId": "54602d6e-ff1d-49f7-a29f-6694862a9b0b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "model_name = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "inputs = tokenizer(\n",
        "        [(query, doc) for doc in context],\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\",\n",
        "        max_length=512,\n",
        "    )\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "with torch.no_grad():\n",
        "      scores = model(**inputs).logits.squeeze(-1)\n",
        "scored_docs = sorted(zip(context, scores.tolist()), key=lambda x: x[1], reverse=True)\n",
        "top3_doc = [doc for doc, _ in scored_docs[:3]]"
      ],
      "metadata": {
        "id": "dYSSJF3Cmi61"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 4"
      ],
      "metadata": {
        "id": "1X5O72P6nqV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OksYkQpfnA8V",
        "outputId": "ed279fc2-eaa5-4626-947d-09a350f5af5b"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.27.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "query_embedding = model.encode(query, convert_to_tensor=True)\n",
        "doc_embeddings = model.encode(context, convert_to_tensor=True)\n",
        "similarities = util.cos_sim(query_embedding, doc_embeddings)[0].cpu().numpy()\n",
        "scored_docs = sorted(\n",
        "        zip(context, similarities), key=lambda x: x[1], reverse=True\n",
        "    )\n",
        "top3_doc = [doc for doc, _ in scored_docs[:3]]"
      ],
      "metadata": {
        "id": "lMklx4NVn6GV"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 5"
      ],
      "metadata": {
        "id": "0Xcb1ABtpyyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0i1vH7-loGiF",
        "outputId": "4cac3633-0dca-4a0e-cf6e-9a38cbba86e4"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "query_doc = nlp(query)\n",
        "scored_docs = sorted(\n",
        "        context,\n",
        "        key=lambda doc: query_doc.similarity(nlp(doc)),\n",
        "        reverse=True,\n",
        "    )\n",
        "top3_doc = scored_docs[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsDVjMOEp32W",
        "outputId": "c134d91d-1f31-496b-a88e-fc4a9a413bad"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What is a CV? \"CV\" stands for curriculum vitae. This Latin phrase is the technical meaning of a CV and stands for \"course of life.\" So, what does a CV mean on a job application?It\\'s a detailed summary of your academic and professional life — this document usually is more than two pages long.',\n",
              " 'A CV is a detailed document highlighting your professional and academic history, while a resume is a summary of your skills and experience. Learn when to use a CV, how to format it and see examples of both.',\n",
              " 'A curriculum vitae (CV) is a detailed list of your achievements, education, and work experience. Learn when and how to use a CV, and see a sample CV for academia.']"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4h7_81Lcp9QW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}