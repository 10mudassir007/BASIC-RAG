{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "etGcGCaqARzP"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index llama-index-llms-groq llama-index-vector-stores-faiss faiss-cpu llama-index-embeddings-huggingface -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['GROQ_API_KEY'] = userdata.get('GROQ_API_KEY')"
      ],
      "metadata": {
        "id": "WUSQ2TylTEKE"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "reader = SimpleDirectoryReader(input_dir=\"/content/\")\n",
        "documents = reader.load_data()"
      ],
      "metadata": {
        "id": "Aiz2sOYiFd69"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.vector_stores.faiss import FaissVectorStore\n",
        "from llama_index.core import StorageContext,VectorStoreIndex,KnowledgeGraphIndex,ServiceContext\n",
        "import faiss\n",
        "\n",
        "embeddings = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "vector_store = VectorStoreIndex.from_documents(documents=documents,embed_model=embeddings)"
      ],
      "metadata": {
        "id": "3VYzAyqNJ015"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.groq import Groq\n",
        "\n",
        "llm = Groq(model='llama-3.2-1b-preview')"
      ],
      "metadata": {
        "id": "x_7WEbbzJ7U4"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import PromptTemplate\n",
        "\n",
        "template = (\n",
        "    \"We have provided context information below. \\n\"\n",
        "    \"---------------------\\n\"\n",
        "    \"{context}\"\n",
        "    \"\\n---------------------\\n\"\n",
        "    \"Given this information, please answer the question: {query}\\n\"\n",
        ")\n",
        "\n",
        "qa_template = PromptTemplate(template)"
      ],
      "metadata": {
        "id": "BAG5oYBfTapz"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = vector_store.as_query_engine(llm=llm,prompt=qa_template)"
      ],
      "metadata": {
        "id": "b7ZKwROrPM1F"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine.query('what is this document about?').response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "OVWAYkLLUUXS",
        "outputId": "7050c006-7f8a-493c-d81b-77e3b4f93f9b"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This document appears to be a resume for Mudassir Junejo, a Machine Learning Engineer with expertise in various areas, including computer vision, natural language processing, and predictive analytics.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    }
  ]
}